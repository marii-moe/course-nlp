{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of my results:\n",
    "\n",
    "model            | train_loss | valid_loss | seq2seq_acc | bleu\n",
    "-------------------|----------|----------|----------|----------\n",
    "seq2seq            | 3.355085 | 4.272877 | 0.382089 | 0.291899\n",
    "\\+ teacher forcing | 3.154585 |\t4.022432 | 0.407792 | 0.310715\n",
    "\\+ attention       | 1.452292 | 3.420485 | 0.498205 | 0.413232\n",
    "transformer        | 1.913152 | 2.349686 | 0.781749 | 0.612880"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Translation with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention is a technique that uses the output of our encoder: instead of discarding it entirely, we use it with our hidden state to pay attention to specific words in the input sentence for the predictions in the output sentence. Specifically, we compute attention weights, then add to the input of the decoder the linear combination of the output of the encoder, with those attention weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice illustration of attention comes from [this blog post](http://jalammar.github.io/illustrated-transformer/) by Jay Alammar (visualization originally from [Tensor2Tensor notebook](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb)):\n",
    "\n",
    "<img src=\"images/alammar-attention.png\" alt=\"attention\" style=\"width: 60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second things that might help is to use a bidirectional model for the encoder. We set the `bidrectional` parameter to `True` for our GRU encoder, and double the number of inputs to the linear output layer of the encoder.\n",
    "\n",
    "Also, we now need to set our hidden state:\n",
    "\n",
    "```\n",
    "hid = hid.view(2,self.n_layers, bs, self.n_hid).permute(1,2,0,3).contiguous()\n",
    "hid = self.out_enc(self.hid_dp(hid).view(self.n_layers, bs, 2*self.n_hid))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to re-run from start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Config().data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Config().data_path()/'giga-fren'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=True, backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    samples = to_data(samples)\n",
    "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
    "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
    "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
    "    if backwards: pad_first = not pad_first\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "        else:         \n",
    "            res_x[i,:len(s[0])],res_y[i,:len(s[1])] = LongTensor(s[0]),LongTensor(s[1])\n",
    "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
    "    return res_x,res_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataBunch(TextDataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1,\n",
    "               dl_tfms=None, pad_first=False, device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
    "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch\n",
    "    _label_cls = TextList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/molly/.fastai/data/giga-fren')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(path/'giga-fren')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/molly/.fastai/models')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Config().model_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(8144, 300, padding_idx=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_enc = torch.load(model_path/'fr_emb.pth')\n",
    "emb_dec = torch.load(model_path/'en_emb.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(out, targ, pad_idx=1):\n",
    "    bs,targ_len = targ.size()\n",
    "    _,out_len,vs = out.size()\n",
    "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
    "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
    "    return CrossEntropyFlat()(out, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_acc(out, targ, pad_idx=1):\n",
    "    bs,targ_len = targ.size()\n",
    "    _,out_len,vs = out.size()\n",
    "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
    "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
    "    out = out.argmax(2)\n",
    "    return (out==targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGram():\n",
    "    def __init__(self, ngram, max_n=5000): self.ngram,self.max_n = ngram,max_n\n",
    "    def __eq__(self, other):\n",
    "        if len(self.ngram) != len(other.ngram): return False\n",
    "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
    "    def __hash__(self): return int(sum([o * self.max_n**i for i,o in enumerate(self.ngram)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grams(x, n, max_n=5000):\n",
    "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_ngrams(pred, targ, n, max_n=5000):\n",
    "    pred_grams,targ_grams = get_grams(pred, n, max_n=max_n),get_grams(targ, n, max_n=max_n)\n",
    "    pred_cnt,targ_cnt = Counter(pred_grams),Counter(targ_grams)\n",
    "    return sum([min(c, targ_cnt[g]) for g,c in pred_cnt.items()]),len(pred_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(learn, ds_type=DatasetType.Valid):\n",
    "    learn.model.eval()\n",
    "    inputs, targets, outputs = [],[],[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in progress_bar(learn.dl(ds_type)):\n",
    "            out = learn.model(xb)\n",
    "            for x,y,z in zip(xb,yb,out):\n",
    "                inputs.append(learn.data.train_ds.x.reconstruct(x))\n",
    "                targets.append(learn.data.train_ds.y.reconstruct(y))\n",
    "                outputs.append(learn.data.train_ds.y.reconstruct(z.argmax(1)))\n",
    "    return inputs, targets, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusBLEU(Callback):\n",
    "    def __init__(self, vocab_sz):\n",
    "        self.vocab_sz = vocab_sz\n",
    "        self.name = 'bleu'\n",
    "    \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.pred_len,self.targ_len,self.corrects,self.counts = 0,0,[0]*4,[0]*4\n",
    "    \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        last_output = last_output.argmax(dim=-1)\n",
    "        for pred,targ in zip(last_output.cpu().numpy(),last_target.cpu().numpy()):\n",
    "            self.pred_len += len(pred)\n",
    "            self.targ_len += len(targ)\n",
    "            for i in range(4):\n",
    "                c,t = get_correct_ngrams(pred, targ, i+1, max_n=self.vocab_sz)\n",
    "                self.corrects[i] += c\n",
    "                self.counts[i]   += t\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        precs = [c/t for c,t in zip(self.corrects,self.counts)]\n",
    "        len_penalty = exp(1 - self.targ_len/self.pred_len) if self.pred_len < self.targ_len else 1\n",
    "        bleu = len_penalty * ((precs[0]*precs[1]*precs[2]*precs[3]) ** 0.25)\n",
    "        return add_metrics(last_metrics, bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherForcing(LearnerCallback):\n",
    "    def __init__(self, learn, end_epoch):\n",
    "        super().__init__(learn)\n",
    "        self.end_epoch = end_epoch\n",
    "    \n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        if train: return {'last_input': [last_input, last_target]}\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, **kwargs):\n",
    "        self.learn.model.pr_force = 1 - epoch/self.end_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_attn(nn.Module):\n",
    "    def __init__(self, emb_enc, emb_dec, nh, out_sl, nl=2, bos_idx=0, pad_idx=1):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl,self.pr_force = nl,nh,out_sl,1\n",
    "        self.bos_idx,self.pad_idx = bos_idx,pad_idx\n",
    "        self.emb_enc,self.emb_dec = emb_enc,emb_dec\n",
    "        self.emb_sz_enc,self.emb_sz_dec = emb_enc.embedding_dim,emb_dec.embedding_dim\n",
    "        self.voc_sz_dec = emb_dec.num_embeddings\n",
    "                 \n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(self.emb_sz_enc, nh, num_layers=nl, dropout=0.25, \n",
    "                              batch_first=True, bidirectional=True)\n",
    "        self.out_enc = nn.Linear(2*nh, self.emb_sz_dec, bias=False)\n",
    "        \n",
    "        self.gru_dec = nn.GRU(self.emb_sz_dec + 2*nh, self.emb_sz_dec, num_layers=nl,\n",
    "                              dropout=0.1, batch_first=True)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(self.emb_sz_dec, self.voc_sz_dec)\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "        self.enc_att = nn.Linear(2*nh, self.emb_sz_dec, bias=False)\n",
    "        self.hid_att = nn.Linear(self.emb_sz_dec, self.emb_sz_dec)\n",
    "        self.V =  self.init_param(self.emb_sz_dec)\n",
    "        \n",
    "    def encoder(self, bs, inp):\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, hid = self.gru_enc(emb, 2*h)\n",
    "        \n",
    "        pre_hid = hid.view(2, self.nl, bs, self.nh).permute(1,2,0,3).contiguous()\n",
    "        pre_hid = pre_hid.view(self.nl, bs, 2*self.nh)\n",
    "        hid = self.out_enc(pre_hid)\n",
    "        return hid,enc_out\n",
    "    \n",
    "    def decoder(self, dec_inp, hid, enc_att, enc_out):\n",
    "        hid_att = self.hid_att(hid[-1])\n",
    "        # we have put enc_out and hid through linear layers\n",
    "        u = torch.tanh(enc_att + hid_att[:,None])\n",
    "        # we want to learn the importance of each time step\n",
    "        attn_wgts = F.softmax(u @ self.V, 1)\n",
    "        # weighted average of enc_out (which is the output at every time step)\n",
    "        import pdb; pdb.set_trace()\n",
    "        ctx = (attn_wgts[...,None] * enc_out).sum(1)\n",
    "        emb = self.emb_dec(dec_inp)\n",
    "        # concatenate decoder embedding with context (we could have just\n",
    "        # used the hidden state that came out of the decoder, if we weren't\n",
    "        # using attention)\n",
    "        outp, hid = self.gru_dec(torch.cat([emb, ctx], 1)[:,None], hid)\n",
    "        outp = self.out(self.out_drop(outp[:,0]))\n",
    "        return hid, outp\n",
    "        \n",
    "    def show(self, nm,v):\n",
    "        if False: print(f\"{nm}={v[nm].shape}\")\n",
    "        \n",
    "    def forward(self, inp, targ=None):\n",
    "        import pdb;pdb.set_trace()\n",
    "        bs, sl = inp.size()\n",
    "        hid,enc_out = self.encoder(bs, inp)\n",
    "#        self.show(\"hid\",vars())\n",
    "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "        enc_att = self.enc_att(enc_out)\n",
    "        \n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            hid, outp = self.decoder(dec_inp, hid, enc_att, enc_out)\n",
    "            res.append(outp)\n",
    "            dec_inp = outp.max(1)[1]\n",
    "            if (dec_inp==self.pad_idx).all(): break\n",
    "            if (targ is not None) and (random.random()<self.pr_force):\n",
    "                if i>=targ.shape[1]: continue\n",
    "                dec_inp = targ[:,i]\n",
    "        return torch.stack(res, dim=1)\n",
    "\n",
    "    def initHidden(self, bs): return one_param(self).new_zeros(2*self.nl, bs, self.nh)\n",
    "    def init_param(self, *sz): return nn.Parameter(torch.randn(sz)/math.sqrt(sz[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "hid=torch.Size([2, 64, 300])\n",
    "dec_inp=torch.Size([64])\n",
    "enc_att=torch.Size([64, 30, 300])\n",
    "hid_att=torch.Size([64, 300])\n",
    "u=torch.Size([64, 30, 300])\n",
    "attn_wgts=torch.Size([64, 30])\n",
    "enc_out=torch.Size([64, 30, 512])\n",
    "ctx=torch.Size([64, 512])\n",
    "emb=torch.Size([64, 300])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 30, 512])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.randn([64,30,512]),1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get bs and sl, batchsize and sequence length. \n",
    "2. Get encoder hidden state, and output. Output would be used to predict next word normally. \n",
    "3. dec_inp starts with beginning of string token. \n",
    "4. self.enc_att is just your run of the mill linear layer, notice output features is same as emb_sz_dec\n",
    "5. res is for looping over out_sl\n",
    "6. self.hid_att is another linear layer, -1 is for the last layer of hidden state. \n",
    "7. for u '+' acts as a skip connection. Allows us to either use important information from encoder, or last hidden state. IF hidden is more important it will get grads, encoder otherwise. \n",
    "8. attn_wgts uses softmax to \"pick few\", then weights them accordingly. self.V is just randomly initialized. It is a matrix multiply, so like a linear layer without bias. \n",
    "9. '...' goes to the end, weighted average over seq len\n",
    "10. emb = embedding for input, so beginning of string on first pass\n",
    "11. go through gru with everything we have, emb prev token, ctx attention on encoder/hiddenstate, hid simply hidden state. self.out,self.out_drop, both your run of the mill linear/dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-66-269a9c372a0a>\u001b[0m(57)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     55 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     56 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 57 \u001b[0;31m        \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     58 \u001b[0;31m        \u001b[0mhid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     59 \u001b[0;31m\u001b[0;31m#        self.show(\"hid\",vars())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> continue\n",
      "> \u001b[0;32m<ipython-input-66-269a9c372a0a>\u001b[0m(43)\u001b[0;36mdecoder\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     41 \u001b[0;31m        \u001b[0;31m# weighted average of enc_out (which is the output at every time step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     42 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 43 \u001b[0;31m        \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattn_wgts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     44 \u001b[0;31m        \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     45 \u001b[0;31m        \u001b[0;31m# concatenate decoder embedding with context (we could have just\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> p attn_wgts.shape\n",
      "torch.Size([64, 30])\n",
      "ipdb> p self.V.shape\n",
      "torch.Size([300])\n",
      "ipdb> p (u @ self.V).shape\n",
      "torch.Size([64, 30])\n",
      "ipdb> p u.shape\n",
      "torch.Size([64, 30, 300])\n",
      "ipdb> p self.V.shape\n",
      "torch.Size([300])\n",
      "ipdb> run\n"
     ]
    },
    {
     "ename": "Restart",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestart\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-950c74415431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2SeqRNN_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/fastai1-6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-269a9c372a0a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, targ)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mhid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m#        self.show(\"hid\",vars())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-269a9c372a0a>\u001b[0m in \u001b[0;36mdecoder\u001b[0;34m(self, dec_inp, hid, enc_att, enc_out)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# weighted average of enc_out (which is the output at every time step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattn_wgts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# concatenate decoder embedding with context (we could have just\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-269a9c372a0a>\u001b[0m in \u001b[0;36mdecoder\u001b[0;34m(self, dec_inp, hid, enc_att, enc_out)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# weighted average of enc_out (which is the output at every time step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattn_wgts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# concatenate decoder embedding with context (we could have just\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai1-6/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai1-6/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai1-6/lib/python3.6/pdb.py\u001b[0m in \u001b[0;36muser_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_mainpyfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbp_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbp_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai1-6/lib/python3.6/site-packages/IPython/core/debugger.py\u001b[0m in \u001b[0;36minteraction\u001b[0;34m(self, frame, traceback)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minteraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mOldPdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai1-6/lib/python3.6/pdb.py\u001b[0m in \u001b[0;36minteraction\u001b[0;34m(self, frame, traceback)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_stack_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmdloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai1-6/lib/python3.6/site-packages/IPython/core/debugger.py\u001b[0m in \u001b[0;36m_cmdloop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0;31m# the current command, so allow them during interactive input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_kbdint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmdloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_kbdint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai1-6/lib/python3.6/site-packages/IPython/core/debugger.py\u001b[0m in \u001b[0;36mcmdloop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;34m\"\"\"Wrap cmdloop() such that KeyboardInterrupt stops the debugger.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mOldPdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmdloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai1-6/lib/python3.6/cmd.py\u001b[0m in \u001b[0;36mcmdloop\u001b[0;34m(self, intro)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monecmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                 \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostcmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai1-6/lib/python3.6/pdb.py\u001b[0m in \u001b[0;36monecmd\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \"\"\"\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommands_defining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monecmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_command_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai1-6/lib/python3.6/cmd.py\u001b[0m in \u001b[0;36monecmd\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memptyline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai1-6/lib/python3.6/pdb.py\u001b[0m in \u001b[0;36mdo_run\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margv0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;31m# this is caught in the main debugger loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRestart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0mdo_restart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRestart\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model.eval() could be used to turn off dropout/bn\n",
    "model = Seq2SeqRNN_attn(emb_enc, emb_dec, 256, 30).cpu()\n",
    "with torch.no_grad():\n",
    "    model(data.one_batch()[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 30]), torch.Size([64, 30]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.one_batch()[0].shape,data.one_batch()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Seq2SeqRNN_attn(emb_enc, emb_dec, 256, 30)\n",
    "learn = Learner(data, model, loss_func=seq2seq_loss, metrics=[seq2seq_acc, CorpusBLEU(len(data.y.vocab.itos))],\n",
    "                callback_fns=partial(TeacherForcing, end_epoch=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='77' class='' max='604' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      12.75% [77/604 00:11<01:19 34.1904]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.696383</td>\n",
       "      <td>4.485054</td>\n",
       "      <td>0.478197</td>\n",
       "      <td>0.317973</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.272829</td>\n",
       "      <td>3.627687</td>\n",
       "      <td>0.480260</td>\n",
       "      <td>0.260953</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.001777</td>\n",
       "      <td>3.223874</td>\n",
       "      <td>0.543410</td>\n",
       "      <td>0.339225</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.798534</td>\n",
       "      <td>3.743012</td>\n",
       "      <td>0.515390</td>\n",
       "      <td>0.399688</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.704829</td>\n",
       "      <td>3.880418</td>\n",
       "      <td>0.499043</td>\n",
       "      <td>0.418253</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.554801</td>\n",
       "      <td>3.485410</td>\n",
       "      <td>0.516689</td>\n",
       "      <td>0.433566</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.545516</td>\n",
       "      <td>3.441090</td>\n",
       "      <td>0.527040</td>\n",
       "      <td>0.440249</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.471138</td>\n",
       "      <td>3.582165</td>\n",
       "      <td>0.503292</td>\n",
       "      <td>0.436550</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.431429</td>\n",
       "      <td>3.730690</td>\n",
       "      <td>0.494853</td>\n",
       "      <td>0.436833</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.308023</td>\n",
       "      <td>3.621066</td>\n",
       "      <td>0.498048</td>\n",
       "      <td>0.441744</td>\n",
       "      <td>01:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.282570</td>\n",
       "      <td>3.608853</td>\n",
       "      <td>0.499445</td>\n",
       "      <td>0.444503</td>\n",
       "      <td>01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.200952</td>\n",
       "      <td>3.668440</td>\n",
       "      <td>0.496731</td>\n",
       "      <td>0.443979</td>\n",
       "      <td>01:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.088240</td>\n",
       "      <td>3.608516</td>\n",
       "      <td>0.499809</td>\n",
       "      <td>0.447699</td>\n",
       "      <td>01:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.078471</td>\n",
       "      <td>3.650966</td>\n",
       "      <td>0.493989</td>\n",
       "      <td>0.445128</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.127465</td>\n",
       "      <td>3.653652</td>\n",
       "      <td>0.492920</td>\n",
       "      <td>0.443907</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(15, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(learn, ds_type=DatasetType.Valid):\n",
    "    learn.model.eval()\n",
    "    inputs, targets, outputs = [],[],[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in progress_bar(learn.dl(ds_type)):\n",
    "            out = learn.model(xb)\n",
    "            for x,y,z in zip(xb,yb,out):\n",
    "                inputs.append(learn.data.train_ds.x.reconstruct(x.cpu()))\n",
    "                targets.append(learn.data.train_ds.y.reconstruct(y.cpu()))\n",
    "                outputs.append(learn.data.train_ds.y.reconstruct(z.argmax(1).cpu()))\n",
    "    return inputs, targets, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='151' class='' max='151' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [151/151 00:10<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, targets, outputs = get_predictions(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weird_print(*strs): print('-------',*strs,'-------',sep='\\n--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "--xxbos qui a le pouvoir de modifier le rglement sur les poids et mesures et le rglement sur l'inspection de l'lectricit et du gaz ?\n",
      "--xxbos who has the authority to change the electricity and gas inspection regulations and the weights and measures regulations ?\n",
      "--xxbos who has the authority to change the on and and and regulations and regulations ?\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "weird_print(inputs[700], targets[700], outputs[700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "--xxbos  ` ou sont xxunk leurs grandes convictions en ce qui a trait a la ` `  transparence et a la responsabilite ?\n",
      "--xxbos what happened to their great xxunk about transparency and accountability ?\n",
      "--xxbos what is the xxunk or its accountability ?\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "weird_print(inputs[701], targets[701], outputs[701])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "--xxbos quelles ressources votre communaut possde - t - elle qui favoriseraient la gurison ?\n",
      "--xxbos what resources exist in your community that would promote recovery ?\n",
      "--xxbos what resources resources did your community have to encourage the healing ?\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "weird_print(inputs[4002], targets[4002], outputs[4002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
